# 5.2 인공신경망

## 5.2.1-1 신경망을 통한 AND OR 문제
	(인공신경망 개요와 뉴런, 단층 퍼셉트론)

#### 퍼셉트론 : 선형적인 패턴을 구분하는 방식
	->단점 : 비선형적인 패턴 분석 어려움.
	->해결 : BackPropagation(역전파 알고리즘) 활용

#### 인공신경망 :
- 인간 뇌를 기반으로 한 추론 모델
- 인간 뇌의 추론 모델=뉴런
- 뉴런은 기본적인 정보처리 단위

#### 인간의 뇌 모델링 :
- 인공 신경망은 뉴런이라는 아주 단순하지만 내부적으로 매우 복잡하게 연결된 프로세스들로 이루어져 있음.
- 뉴런은 가중치가 있는 링크들로 연결되어 있음.
- 각각의 뉴런은 연결을 통해 여러 입력 신호를 받지만 출력 신호는 오직 하나만 생성
- 인공 신경망 구조

#### 인공신경망의 학습 :
- 신경망은 가중치를 반복적으로 조정하여 학습
- 뉴런은 링크로 연결되어 있고, 각 링크에는 그와 연관된 수치적인 가중치가 있음.
- 가중치는 장기 기억을 위한 기본적인 수단으로 각 뉴런 입력 강도, 즉 중요도를 표현

#### 인공신경망의 가중치 조정 :
- 신경망의 가중치를 초기화하고 훈련 예제들의 집합에서 해당 가중치를 갱신
- 신경망의 구조를 먼저 선택하고, 어떤 학습 알고리즘을 사용할지 결정한 후 신경망을 훈련시킴.

#### 뉴런의 특징 :
- 입력 링크에서 여러 신호를 받아서 새로운 활성화 수준을 계산하고, 출력 링크로 출력 신호를 보냄.
- 입력신호는 미가공 데이터 또는 다른 뉴런의 출력이 될 수 있음.
- 출력신호는 문제의 채종적인 해가 되거나 다른 뉴런에 입력 될 수 있음.
![image](https://user-images.githubusercontent.com/51112316/60862766-9d846780-a259-11e9-9718-ddf9647f5eff.png)

####뉴런의 계산 :
- 뉴런은 전이함수, 즉 활성화함수를 사용.
- 활성화 함수를 이용한 출력 결정 순서
	1) 뉴런은 입력신호의 가중치 합을 계산하여 임계값과 비교
	2) 가중치 합이 임계값보다 작으면 뉴런의 출력은 –1, 같거나 크면 +1을 출력함.
- 활성화 함수
![image](https://user-images.githubusercontent.com/51112316/60862799-b7be4580-a259-11e9-8597-053987d1dfcc.png)
![image](https://user-images.githubusercontent.com/51112316/60862807-c0168080-a259-11e9-8f14-4b3c276f1c92.png)

#### 단일 뉴런의 학습(단층 퍼셉트론) :
- 퍼셉트론은 선형 결합기와 하드 리미터(ex.활성화함수)로 구성
- 초평면(hyperplane)으로 n차원 공간을 두 개의 결정 영역으로 나눔

![image](https://user-images.githubusercontent.com/51112316/60862835-d91f3180-a259-11e9-996b-b36c1e83655a.png)
### -> 위의 구조가 초평면(hyperplane)


- 입력이 2개일 때와 3개일 EO의 퍼셉트론 도식화
![image](https://user-images.githubusercontent.com/51112316/60862878-ec320180-a259-11e9-88fa-1d9bd035b7dc.png)

### 퍼셉트론 내에서 AND 연산자 학습(임계값 θ : 0.2, α : 01)
![image](https://user-images.githubusercontent.com/51112316/60862896-fbb14a80-a259-11e9-8258-88d55d1621e8.png)
### 수많은 hyperplane 존재
### -> 점선(----)의 기울기를 가진 plane이 최적의 hyperplane
### -> 붉은 선 : 최적의 hyperplane으로 유추 가능.


![image](https://user-images.githubusercontent.com/51112316/60862936-197eaf80-a25a-11e9-8de6-6568248177a9.png)






## - 간단한 예제 : 

### 초기값을 임의로 지정한 후 확인

![image](https://user-images.githubusercontent.com/51112316/60862985-3b783200-a25a-11e9-86d8-34712ae5d464.png)
### -> 초기값에 대한 결과값
![image](https://user-images.githubusercontent.com/51112316/60863001-44690380-a25a-11e9-9be1-cf9aa3254789.png)
### -> 목표출력값 : 0, 실제출력값 : 0
### -> 오차 : 0
### -> 가중치 변경없이 학습 진행
![image](https://user-images.githubusercontent.com/51112316/60863014-5054c580-a25a-11e9-9199-766c259d9123.png)
![image](https://user-images.githubusercontent.com/51112316/60863019-521e8900-a25a-11e9-9ddf-9761433766a0.png)
### -> 목표출력값 : 0, 실제출력값 : 0
### -> 오차 : 0
### -> 가중치 변경없이 학습 진행
![image](https://user-images.githubusercontent.com/51112316/60863041-5fd40e80-a25a-11e9-88dd-123df34f275e.png)
### -> 목표출력값 : 0, 실제출력값 : 1
### -> 오차 : -1
### -> 가중치 변경 후 진행.
### -> 영향을 미친 가중치 : w1 
### -> w1 가중치 변경 : 기존의 w1+(학슙률*오차)
### -> 이후 다시 진행
![image](https://user-images.githubusercontent.com/51112316/60863071-737f7500-a25a-11e9-9837-fcc0cbcced52.png)
### -> 오차 : 1
### -> w1, w2 모두 활성화 되어 오차 발생
### -> 두 가중치 모두 다 변경


## ->이것으로 하나의 데이터에 대해서 1회(에폭) 완료
## -> 위 작업을 이후 계속 반복

![image](https://user-images.githubusercontent.com/51112316/60863099-85f9ae80-a25a-11e9-898a-3cc91e9244de.png)
![image](https://user-images.githubusercontent.com/51112316/60863103-8b56f900-a25a-11e9-9320-e8ccad66cdb5.png)

## => 퍼셉트론을 여러개로 뭉쳐서 이 문제 해결 가능.
